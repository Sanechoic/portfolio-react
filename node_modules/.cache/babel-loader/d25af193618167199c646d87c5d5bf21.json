{"ast":null,"code":"var _jsxFileName = \"/Users/william/Documents/GitHub/portfolio/src/components/projects/blueNote.js\";\nimport React from 'react'; // Import the Component component from React\n\nimport ProjectCarousel from './../projectPage/projectCarousel.js';\nimport SlideVideo from './../projectPage/slideVideo.js';\nimport SlideImage from './../projectPage/slideImage.js';\n\nfunction BalancingRobot(props) {\n  const slides = [/*#__PURE__*/React.createElement(SlideVideo, {\n    src: require('./../../content/projects/blueNote/hero.mp4'),\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 8,\n      columnNumber: 5\n    }\n  }), /*#__PURE__*/React.createElement(SlideImage, {\n    src: require('./../../content/projects/blueNote/4.png'),\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 11,\n      columnNumber: 5\n    }\n  }), /*#__PURE__*/React.createElement(SlideImage, {\n    src: require('./../../content/projects/blueNote/5.png'),\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 14,\n      columnNumber: 5\n    }\n  }), /*#__PURE__*/React.createElement(SlideImage, {\n    src: require('./../../content/projects/blueNote/6.png'),\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 17,\n      columnNumber: 5\n    }\n  }), /*#__PURE__*/React.createElement(SlideImage, {\n    src: require('./../../content/projects/blueNote/7.png'),\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 20,\n      columnNumber: 5\n    }\n  }), /*#__PURE__*/React.createElement(SlideImage, {\n    src: require('./../../content/projects/blueNote/8.png'),\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 23,\n      columnNumber: 5\n    }\n  }), /*#__PURE__*/React.createElement(SlideImage, {\n    src: require('./../../content/projects/blueNote/9.png'),\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 26,\n      columnNumber: 5\n    }\n  }), /*#__PURE__*/React.createElement(SlideImage, {\n    src: require('./../../content/projects/blueNote/10.png'),\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 29,\n      columnNumber: 5\n    }\n  }), /*#__PURE__*/React.createElement(SlideImage, {\n    src: require('./../../content/projects/blueNote/3.png'),\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 32,\n      columnNumber: 5\n    }\n  }), /*#__PURE__*/React.createElement(SlideImage, {\n    src: require('./../../content/projects/blueNote/2.png'),\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 35,\n      columnNumber: 5\n    }\n  })];\n  const slideInfo = [{\n    text: [],\n    width: '35vw',\n    top: '20vh'\n  }, {\n    text: ['Tube Lines', \"The primary actuation is the notification sent to the phone via the app in the instance of a disruption to a selected line, as well as the user coming into the lounge with their phone between 0700 and 1000. The BLE beacons must all be detected before a notification will send. The app was built using Flutter to have a shared codebase for IOS and Android. Users can select the tube lines which they would like to receive notifications from in the event of disruption.\"],\n    width: '30vw',\n    top: '10vh'\n  }, {\n    text: [\"BLE Beacons\", \"Users can select which bluetooth beacons to use for position detecting.\"],\n    width: '30vw',\n    top: '10vh'\n  }, {\n    text: ['Notifications', ''],\n    width: '30vw',\n    top: '10vh'\n  }, {\n    text: ['Notifications', ''],\n    width: '30vw',\n    top: '10vh'\n  }, {\n    text: ['Notifications', ''],\n    width: '30vw',\n    top: '10vh'\n  }, {\n    text: ['TFL Data - Predicting Disruption', \"In order to estimate to probability of disruption between any given hour of the day, any disruption was modelled as 1 and good service as 0. The proportion of readings during any given hour that are disruptive is used to estimate the probability of disruption. The disruption is minimal in the small hours of the morning when only a few of the lines are running a night service and the majority of the lines are closed. The disruption rate rises to a peak of roughly 0.3 (30%) at 0900, and falls sharply, evening out in the mid afternoon and decreasing more steadily. A potential inference from this is that the disruptions are generally as a result of “rush-hour” in the morning where frayed tensions and congestion dramatically increase the chance of disruption. This model fits well with existing intuition and thus may not be used directly but can confirm that between 0700 and 1000 are suitable times for an alert window (although the user will be able to adjust this interval).\"],\n    width: '30vw',\n    top: '10vh'\n  }, {\n    text: ['BLE Data - Detecting Location', \"There are three main areas where my phone is usually located: the lounge, the attic or the bedroom. As such, for the K-Means clustering feature identification process, the number of clusters was set at 3. By inference from the RSSI values, the clusters could be identified. The cluster with the highest (least negative) lounge RSSI values must be the lounge, the one with the lowest RSSI values across the board must be the attic and final the section with the highest bedroom RSSI values must be the bedroom.\"],\n    width: '30vw',\n    top: '10vh'\n  }, {\n    text: [\"System Diagram\", \"The app allows you to select which tube lines you would like notifications for. In the event that there is a disruption to one of those lines and other configurable conditions are met (e.g. you are downstairs between 0700 and 1000) then a group alert will be generated with one entry for each selected tube line with a description of the delay. Likewise the user selects which BLE devices are the ones to use for triangulation. BLE is used because it doesn’t consume much battery, little information needs to be sent in this application and no connection needs to be maintained for the app to work. The main communications protocols employed are HTTP and BLE. Each BLE scan triggers a corresponding HTTP POST request that sends data to the respective database. TFL API data and BLE RSSI (Signal Strength) data are collected periodically by the phone app. All TFL API data is collected whereas only selected BLE devices have their RSSI, service and characteristic information stored. When the user loads one of the app pages, the data is retrieved on demand using asynchronous HTTP requests or BLE scans. “Serverless” computing is employed wherever possible to ensure uptime and reduce the maintenance burden. Data can be pulled from the respective databases for analysis.\"],\n    width: '30vw',\n    top: '10vh'\n  }, {\n    text: [\"Data Storage\", \"Tube line status is collected using the TFL API (https://api.tfl.gov.uk). For data analytics, TFL API data was requested every 10 minutes (0.00167 Hz) from 03/12/19 until 29/12/19. This was the maximum rate that could be achieved without incurring significant costs, however is was deemed to be above the required theoretical minimum (Nyquist).The data is stored in AWS (Amazon Web Services) DynamoDB NoSQL tables. The serverless, AWS Lambda script which pulls the data from the TFL API is triggered using an HTTP request with API key authentication periodically from the phone app. Three Bluetooth beacons have been set up in different parts of the house and the phone app periodically checks the respective RSSIs (received signal strength indication) every 5 seconds (0.2 Hz), which are then used as a proxy for distance. From this, the position of the phone can be determined through triangulation.\"],\n    width: '30vw',\n    top: '10vh'\n  }];\n  return /*#__PURE__*/React.createElement(\"div\", {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 127,\n      columnNumber: 5\n    }\n  }, /*#__PURE__*/React.createElement(ProjectCarousel, {\n    projectKey: \"blueNote\",\n    slides: slides,\n    slideInfo: slideInfo,\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 128,\n      columnNumber: 7\n    }\n  }));\n}\n\nexport default BalancingRobot;","map":{"version":3,"sources":["/Users/william/Documents/GitHub/portfolio/src/components/projects/blueNote.js"],"names":["React","ProjectCarousel","SlideVideo","SlideImage","BalancingRobot","props","slides","require","slideInfo","text","width","top"],"mappings":";AAAA,OAAOA,KAAP,MAAkB,OAAlB,C,CAA2B;;AAC3B,OAAOC,eAAP,MAA4B,qCAA5B;AACA,OAAOC,UAAP,MAAuB,gCAAvB;AACA,OAAOC,UAAP,MAAuB,gCAAvB;;AAEA,SAASC,cAAT,CAAwBC,KAAxB,EAA+B;AAC7B,QAAMC,MAAM,GAAG,cACb,oBAAC,UAAD;AACE,IAAA,GAAG,EAAEC,OAAO,CAAC,4CAAD,CADd;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IADa,eAIb,oBAAC,UAAD;AACE,IAAA,GAAG,EAAEA,OAAO,CAAC,yCAAD,CADd;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IAJa,eAOb,oBAAC,UAAD;AACE,IAAA,GAAG,EAAEA,OAAO,CAAC,yCAAD,CADd;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IAPa,eAUb,oBAAC,UAAD;AACE,IAAA,GAAG,EAAEA,OAAO,CAAC,yCAAD,CADd;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IAVa,eAab,oBAAC,UAAD;AACE,IAAA,GAAG,EAAEA,OAAO,CAAC,yCAAD,CADd;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IAba,eAgBb,oBAAC,UAAD;AACE,IAAA,GAAG,EAAEA,OAAO,CAAC,yCAAD,CADd;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IAhBa,eAmBb,oBAAC,UAAD;AACE,IAAA,GAAG,EAAEA,OAAO,CAAC,yCAAD,CADd;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IAnBa,eAsBb,oBAAC,UAAD;AACE,IAAA,GAAG,EAAEA,OAAO,CAAC,0CAAD,CADd;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IAtBa,eAyBb,oBAAC,UAAD;AACE,IAAA,GAAG,EAAEA,OAAO,CAAC,yCAAD,CADd;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IAzBa,eA4Bb,oBAAC,UAAD;AACE,IAAA,GAAG,EAAEA,OAAO,CAAC,yCAAD,CADd;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IA5Ba,CAAf;AAkCA,QAAMC,SAAS,GAAG,CAChB;AACEC,IAAAA,IAAI,EAAC,EADP;AAEEC,IAAAA,KAAK,EAAC,MAFR;AAGEC,IAAAA,GAAG,EAAC;AAHN,GADgB,EAMhB;AACEF,IAAAA,IAAI,EACF,CACE,YADF,EAEE,qdAFF,CAFJ;AAMEC,IAAAA,KAAK,EAAC,MANR;AAOEC,IAAAA,GAAG,EAAC;AAPN,GANgB,EAehB;AACEF,IAAAA,IAAI,EACF,CACE,aADF,EAEE,yEAFF,CAFJ;AAMEC,IAAAA,KAAK,EAAC,MANR;AAOEC,IAAAA,GAAG,EAAC;AAPN,GAfgB,EAwBhB;AACEF,IAAAA,IAAI,EAAC,CACH,eADG,EAEH,EAFG,CADP;AAKEC,IAAAA,KAAK,EAAC,MALR;AAMEC,IAAAA,GAAG,EAAC;AANN,GAxBgB,EAgChB;AACEF,IAAAA,IAAI,EAAC,CACH,eADG,EAEH,EAFG,CADP;AAKEC,IAAAA,KAAK,EAAC,MALR;AAMEC,IAAAA,GAAG,EAAC;AANN,GAhCgB,EAwChB;AACEF,IAAAA,IAAI,EAAC,CACH,eADG,EAEH,EAFG,CADP;AAKEC,IAAAA,KAAK,EAAC,MALR;AAMEC,IAAAA,GAAG,EAAC;AANN,GAxCgB,EAgDhB;AACEF,IAAAA,IAAI,EAAC,CACH,kCADG,EAEH,y9BAFG,CADP;AAMEC,IAAAA,KAAK,EAAC,MANR;AAOEC,IAAAA,GAAG,EAAC;AAPN,GAhDgB,EAyDhB;AACEF,IAAAA,IAAI,EAAC,CACH,+BADG,EAEH,+fAFG,CADP;AAKEC,IAAAA,KAAK,EAAC,MALR;AAMEC,IAAAA,GAAG,EAAC;AANN,GAzDgB,EAiEhB;AACEF,IAAAA,IAAI,EAAC,CACH,gBADG,EAEH,yvCAFG,CADP;AAMEC,IAAAA,KAAK,EAAC,MANR;AAOEC,IAAAA,GAAG,EAAC;AAPN,GAjEgB,EA0EhB;AACEF,IAAAA,IAAI,EAAC,CACH,cADG,EAEH,u4BAFG,CADP;AAMEC,IAAAA,KAAK,EAAC,MANR;AAOEC,IAAAA,GAAG,EAAC;AAPN,GA1EgB,CAAlB;AAqFA,sBACE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kBACE,oBAAC,eAAD;AACE,IAAA,UAAU,EAAC,UADb;AAEE,IAAA,MAAM,EAAEL,MAFV;AAGE,IAAA,SAAS,EAAEE,SAHb;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IADF,CADF;AASD;;AAED,eAAeJ,cAAf","sourcesContent":["import React from 'react'; // Import the Component component from React\nimport ProjectCarousel from './../projectPage/projectCarousel.js'\nimport SlideVideo from './../projectPage/slideVideo.js'\nimport SlideImage from './../projectPage/slideImage.js'\n\nfunction BalancingRobot(props) {\n  const slides = [\n    <SlideVideo\n      src={require('./../../content/projects/blueNote/hero.mp4')}\n    />,\n    <SlideImage\n      src={require('./../../content/projects/blueNote/4.png')}\n    />,\n    <SlideImage\n      src={require('./../../content/projects/blueNote/5.png')}\n    />,\n    <SlideImage\n      src={require('./../../content/projects/blueNote/6.png')}\n    />,\n    <SlideImage\n      src={require('./../../content/projects/blueNote/7.png')}\n    />,\n    <SlideImage\n      src={require('./../../content/projects/blueNote/8.png')}\n    />,\n    <SlideImage\n      src={require('./../../content/projects/blueNote/9.png')}\n    />,\n    <SlideImage\n      src={require('./../../content/projects/blueNote/10.png')}\n    />,\n    <SlideImage\n      src={require('./../../content/projects/blueNote/3.png')}\n    />,\n    <SlideImage\n      src={require('./../../content/projects/blueNote/2.png')}\n    />,\n\n  ]\n\n  const slideInfo = [\n    {\n      text:[],\n      width:'35vw',\n      top:'20vh',\n    },\n    {\n      text:\n        [\n          'Tube Lines',\n          \"The primary actuation is the notification sent to the phone via the app in the instance of a disruption to a selected line, as well as the user coming into the lounge with their phone between 0700 and 1000. The BLE beacons must all be detected before a notification will send. The app was built using Flutter to have a shared codebase for IOS and Android. Users can select the tube lines which they would like to receive notifications from in the event of disruption.\"\n        ],\n      width:'30vw',\n      top:'10vh',\n    },\n    {\n      text:\n        [\n          \"BLE Beacons\",\n          \"Users can select which bluetooth beacons to use for position detecting.\"\n        ],\n      width:'30vw',\n      top:'10vh',\n    },\n    {\n      text:[\n        'Notifications',\n        ''\n      ],\n      width:'30vw',\n      top:'10vh',\n    },\n    {\n      text:[\n        'Notifications',\n        ''\n      ],\n      width:'30vw',\n      top:'10vh',\n    },\n    {\n      text:[\n        'Notifications',\n        ''\n      ],\n      width:'30vw',\n      top:'10vh',\n    },\n    {\n      text:[\n        'TFL Data - Predicting Disruption',\n        \"In order to estimate to probability of disruption between any given hour of the day, any disruption was modelled as 1 and good service as 0. The proportion of readings during any given hour that are disruptive is used to estimate the probability of disruption. The disruption is minimal in the small hours of the morning when only a few of the lines are running a night service and the majority of the lines are closed. The disruption rate rises to a peak of roughly 0.3 (30%) at 0900, and falls sharply, evening out in the mid afternoon and decreasing more steadily. A potential inference from this is that the disruptions are generally as a result of “rush-hour” in the morning where frayed tensions and congestion dramatically increase the chance of disruption. This model fits well with existing intuition and thus may not be used directly but can confirm that between 0700 and 1000 are suitable times for an alert window (although the user will be able to adjust this interval).\"\n\n      ],\n      width:'30vw',\n      top:'10vh',\n    },\n    {\n      text:[\n        'BLE Data - Detecting Location',\n        \"There are three main areas where my phone is usually located: the lounge, the attic or the bedroom. As such, for the K-Means clustering feature identification process, the number of clusters was set at 3. By inference from the RSSI values, the clusters could be identified. The cluster with the highest (least negative) lounge RSSI values must be the lounge, the one with the lowest RSSI values across the board must be the attic and final the section with the highest bedroom RSSI values must be the bedroom.\"\n      ],\n      width:'30vw',\n      top:'10vh',\n    },\n    {\n      text:[\n        \"System Diagram\",\n        \"The app allows you to select which tube lines you would like notifications for. In the event that there is a disruption to one of those lines and other configurable conditions are met (e.g. you are downstairs between 0700 and 1000) then a group alert will be generated with one entry for each selected tube line with a description of the delay. Likewise the user selects which BLE devices are the ones to use for triangulation. BLE is used because it doesn’t consume much battery, little information needs to be sent in this application and no connection needs to be maintained for the app to work. The main communications protocols employed are HTTP and BLE. Each BLE scan triggers a corresponding HTTP POST request that sends data to the respective database. TFL API data and BLE RSSI (Signal Strength) data are collected periodically by the phone app. All TFL API data is collected whereas only selected BLE devices have their RSSI, service and characteristic information stored. When the user loads one of the app pages, the data is retrieved on demand using asynchronous HTTP requests or BLE scans. “Serverless” computing is employed wherever possible to ensure uptime and reduce the maintenance burden. Data can be pulled from the respective databases for analysis.\"\n\n      ],\n      width:'30vw',\n      top:'10vh',\n    },\n    {\n      text:[\n        \"Data Storage\",\n        \"Tube line status is collected using the TFL API (https://api.tfl.gov.uk). For data analytics, TFL API data was requested every 10 minutes (0.00167 Hz) from 03/12/19 until 29/12/19. This was the maximum rate that could be achieved without incurring significant costs, however is was deemed to be above the required theoretical minimum (Nyquist).The data is stored in AWS (Amazon Web Services) DynamoDB NoSQL tables. The serverless, AWS Lambda script which pulls the data from the TFL API is triggered using an HTTP request with API key authentication periodically from the phone app. Three Bluetooth beacons have been set up in different parts of the house and the phone app periodically checks the respective RSSIs (received signal strength indication) every 5 seconds (0.2 Hz), which are then used as a proxy for distance. From this, the position of the phone can be determined through triangulation.\"\n\n      ],\n      width:'30vw',\n      top:'10vh',\n    },\n  ]\n\n  return(\n    <div>\n      <ProjectCarousel\n        projectKey='blueNote'\n        slides={slides}\n        slideInfo={slideInfo}\n      />\n    </div>\n  )\n}\n\nexport default BalancingRobot;\n"]},"metadata":{},"sourceType":"module"}